{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978eb394-c926-471c-9ca9-7635c03ddb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from fastembed import TextEmbedding\n",
    "import os\n",
    "from pinecone import Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from langchain_openai import ChatOpenAI\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import random\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "from dotenv import load_dotenv\n",
    "from langchain import hub\n",
    "import time\n",
    "from typing import List, Dict, Any\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pandas import DataFrame\n",
    "from langchain.docstore.document import Document\n",
    "import torch\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from typing_extensions import TypedDict\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32a2cb8-353c-41aa-af32-7781d19cb2c1",
   "metadata": {},
   "source": [
    "## The following code was used to upsert the dataset onto pinecone as a vector database. The code was showned here to prove its eligibility. In the Python File I uploaded for running the code, the following code was commented as to save time so the whole code can be run in under 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d17707-2f3d-4354-b75b-f5f53372e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"snap/amazon-fine-food-reviews\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccf1afb-b649-4d09-aec7-43710ab55723",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r\"/Users/donnylou/.cache/kagglehub/datasets/snap/amazon-fine-food-reviews/versions/2\"\n",
    "files = os.listdir(dataset_path)\n",
    "print(\"Dataset Files:\", files)\n",
    "file_path = dataset_path + '/Reviews.csv'\n",
    "#file_path = r\"C:\\Users\\hongk\\.cache\\kagglehub\\datasets\\snap\\amazon-fine-food-reviews\\versions\\2\\Reviews.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2b61a7-66d6-4e7e-ab93-8fde8f960ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexs = df['Text'].apply(lambda x: len(x)<990)\n",
    "review_df = df[indexs]\n",
    "print(review_df.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838176d0-84db-46c1-b47c-475ab910b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(8889)\n",
    "nrow = len(review_df)\n",
    "embed_index = random.sample(range(1,nrow), 100000)\n",
    "review_embed = review_df.iloc[embed_index,:].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9367f895-4296-41dd-ba52-d6b1c889bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = TextEmbedding(model_name = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e1c35a-1ab1-4419-9244-a97bf96612db",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f21804-a61c-45f1-a06f-51e8b4eb549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_review_chunked_df = pd.DataFrame()\n",
    "batch_size = 2000\n",
    "total_rows = len(review_embed)\n",
    "\n",
    "# Process the DataFrame in batches of `batch_size`\n",
    "for start_idx in range(0, total_rows, batch_size):\n",
    "    print(start_idx)\n",
    "    end_idx = min(start_idx + batch_size, total_rows)\n",
    "    batch = review_embed.iloc[start_idx:end_idx].copy()  # Get a copy of the current batch\n",
    "    \n",
    "    # Calculate embeddings for the current batch\n",
    "    batch.loc[:, 'embedded_text_tedstv2'] = batch['Text'].apply(\n",
    "        lambda x: list(embedding_model.embed(x))\n",
    "    )\n",
    "    final_review_chunked_df = pd.concat([final_review_chunked_df, batch], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962cb606-4754-4ec2-9358-09ffa75b6733",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_review_chunked_df.to_csv('final_review_chunked_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25c5984-6cf4-469a-b801-b7d8a386cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone()\n",
    "\n",
    "\n",
    "cloud = os.environ.get('PINECONE_CLOUD') or 'aws'\n",
    "region = os.environ.get('PINECONE_REGION') or 'us-east-1'\n",
    "\n",
    "spec = ServerlessSpec(cloud=cloud, region=region)\n",
    "embed_dim = 768\n",
    "index_name = 'food-review-info'\n",
    "if index_name in pc.list_indexes().names():\n",
    "    pc.delete_index(index_name)\n",
    "\n",
    "pc.create_index(\n",
    "        index_name,\n",
    "        dimension=embed_dim,  \n",
    "        metric='euclidean',\n",
    "        spec=spec\n",
    "    )\n",
    "# wait a moment for the index to be fully initialized\n",
    "while not pc.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1)\n",
    "index = pc.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbabea1-ebd0-4d83-bfe1-ae8b20eaf3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_list=final_review_chunked_df['embedded_text_tedstv2'].apply(lambda x: x[0])\n",
    "# store the index of the raw text as the metadata\n",
    "metadata=[{\"raw_text_index\": str(i)} for i in range(len(final_review_chunked_df))]\n",
    "data = {'id':[str(i) for i in range(len(embedding_list))], 'values':embedding_list, 'metadata':metadata}\n",
    "dataset = pd.DataFrame(data=data)\n",
    "reserved_df = dataset.iloc[-50:].copy()\n",
    "upsert_df = dataset.iloc[:-50].copy()\n",
    "upsert_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02238614-3fb6-4485-9ada-e466023f7d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.upsert_from_dataframe(upsert_df)\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554a30ae-2fa8-42a5-aa3d-357f499f1e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = index.query(vector=[0.1]*768, top_k=1, include_metadata=True)\n",
    "print(\"Retrieved metadata:\", test_results['matches'][0]['metadata'])\n",
    "print(\"Does it contain the actual text?\", 'text' in test_results['matches'][0]['metadata'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da619adb-be50-4424-8c16-569e71bf4875",
   "metadata": {},
   "source": [
    "## Assuming the dataframe has been upserted to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afe3d75-d03a-414f-b256-ba3252c444a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_review_chunked_df = pd.read_csv('final_review_chunked_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f10ca85-ffc1-4244-a04f-d6f802b83eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone()\n",
    "\n",
    "# Define your index name\n",
    "index_name = 'food-review-info'\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9f0fcb-9fb3-45e9-8483-56cbf7d9c816",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingModel:\n",
    "    def __init__(self, model):\n",
    "        self.model = TextEmbedding(model_name=model)\n",
    "        \n",
    "    def embed_documents(self, splits):\n",
    "        # Use self.model instead of embedding_model\n",
    "        # Also, batch processing if your TextEmbedding supports it would be more efficient\n",
    "        return [list(self.model.embed(split.page_content))[0].tolist() for split in splits]\n",
    "        \n",
    "    def embed_query(self, query):\n",
    "        # This method needs to accept a query string directly, not a Document object\n",
    "        return list(self.model.embed(query))[0].tolist()\n",
    "embeddings = EmbeddingModel(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
    "text_field = \"raw_text_index\"\n",
    "vectorstore = PineconeVectorStore(  \n",
    "    index, embeddings, text_field\n",
    ")  \n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50549ea8-01dd-4151-a414-0fbfbe1b0491",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRetriever(BaseRetriever):\n",
    "    vectorstore: PineconeVectorStore\n",
    "    df: DataFrame\n",
    "\n",
    "    def _get_relevant_documents(self, query):\n",
    "        docs = self.vectorstore.similarity_search(query, k=5)\n",
    "        outputs = []\n",
    "        for doc in docs:\n",
    "        # Retrieve the original text from your DataFrame\n",
    "            raw_text = self.df.loc[int(doc.id), 'Text']\n",
    "        # Turn that into a Document\n",
    "            outputs.append(Document(page_content=raw_text))\n",
    "        return outputs\n",
    "retriever = CustomRetriever(vectorstore=vectorstore, df=final_review_chunked_df)\n",
    "template_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\",  seed=0)\n",
    "rag_chain = template_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1637b3e5-f35e-437c-97b3-526bf2541de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What's the comment about cat food?\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[0].page_content\n",
    "print(doc_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532d0f2f-a69e-4a51-bee2-39aabaf96cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"HuggingFaceTB/SmolLM2-1.7B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenizer.add_eos_token = True\n",
    "tokenizer.pad_token_id = 0\n",
    "tokenizer.padding_side = \"left\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained(checkpoint)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ccfc3-14ad-484b-9a19-555a7e82d643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load your LoRA adapter\n",
    "peft_model_path = \"./my_model\"  # Path to your saved LoRA adapter\n",
    "model = PeftModel.from_pretrained(base_model, peft_model_path)\n",
    "\n",
    "# 3. Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4483f72c-ace5-4ce2-8f55-36e46d2e1cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_params = {\n",
    "    \"max_new_tokens\": 10, \n",
    "    \"temperature\": 0.1,\n",
    "    \"top_p\": 0.9,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.pad_token_id,\n",
    "    \"eos_token_id\": tokenizer.eos_token_id\n",
    "}\n",
    "\n",
    "def score_review(review_text):\n",
    "    # Format the input for the fine-tuned model\n",
    "    question_template = '''\n",
    "    You will be provided Amazon Fine Food Review from a user, and you need to guess the score that user rates from the review. There are 5 possible scores: 1,2,3,4, and 5, where 1 is the \n",
    "    lowest score and 5 is the highest score. You can Identify key descriptive words and phrases, determine the tone or emotion conveyed by these words or phrases,\n",
    "    and summarize how these descriptors combine to reflect an overall sentiment.\n",
    "    Place the score at the end of the response with a space and then the final answer. Like if the score if 4, then give it as:  4 with extra space before 4. \n",
    "    '''\n",
    "    \n",
    "    prompt = question_template + review_text\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    input_text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "    \n",
    "    # Tokenize input\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate attention mask\n",
    "    attention_mask = torch.ones_like(inputs)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(inputs, attention_mask=attention_mask, **generator_params)\n",
    "    \n",
    "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract just the numeric score (1-5)\n",
    "    try:\n",
    "        # Look for the last digit in the result\n",
    "        for char in reversed(result):\n",
    "            if char.isdigit() and int(char) in [1, 2, 3, 4, 5]:\n",
    "                return int(char)\n",
    "        # Default to 3 if no valid score found\n",
    "        return 3\n",
    "    except:\n",
    "        return 3\n",
    "lora_scorer = score_review\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(checkpoint)\n",
    "def score_review_base(review_text):\n",
    "    # Format the input for the fine-tuned model\n",
    "    question_template = '''\n",
    "    You will be provided Amazon Fine Food Review from a user, and you need to guess the score that user rates from the review. There are 5 possible scores: 1,2,3,4, and 5, where 1 is the \n",
    "    lowest score and 5 is the highest score. You can Identify key descriptive words and phrases, determine the tone or emotion conveyed by these words or phrases,\n",
    "    and summarize how these descriptors combine to reflect an overall sentiment.\n",
    "    Place the score at the end of the response with a space and then the final answer. Like if the score if 4, then give it as:  4 with extra space before 4. \n",
    "    '''\n",
    "    \n",
    "    prompt = question_template + review_text\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    input_text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "    \n",
    "    # Tokenize input\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate attention mask\n",
    "    attention_mask = torch.ones_like(inputs)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = base_model.generate(inputs, attention_mask=attention_mask, **generator_params)\n",
    "    \n",
    "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract just the numeric score (1-5)\n",
    "    try:\n",
    "        # Look for the last digit in the result\n",
    "        for char in reversed(result):\n",
    "            if char.isdigit() and int(char) in [1, 2, 3, 4, 5]:\n",
    "                return int(char)\n",
    "        # Default to 3 if no valid score found\n",
    "        return 3\n",
    "    except:\n",
    "        return 3\n",
    "lora_scorer_base = score_review_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02833705-bae4-460e-a55b-2a278e0a8416",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_5 = final_review_chunked_df.Text[3]\n",
    "review_1 = final_review_chunked_df.Text[0]\n",
    "print(review_1)\n",
    "print(review_5)\n",
    "print(score_review(review_1))\n",
    "print(score_review(review_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15700e1-161d-4e43-b890-c26b094b7719",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(review_1)\n",
    "print(review_5)\n",
    "print(score_review_base(review_1))\n",
    "print(score_review_base(review_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edb6a08-3bb3-48b0-8c47-4854957a248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_system = \"\"\"You are an expert at analyzing food product reviews to identify advantages and positive aspects.\n",
    "Extract specific benefits, advantages, and positive qualities mentioned in the review.\n",
    "Focus on aspects like taste, quality, value, convenience, nutritional benefits, or unique selling points.\n",
    "Be specific and detail-oriented in your analysis.\"\"\"\n",
    "\n",
    "positive_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", positive_system),\n",
    "    (\"human\", \"Review: {review}\\n\\nWhat specific advantages or positive aspects are mentioned in this review?\")\n",
    "])\n",
    "\n",
    "# Prompt for analyzing disadvantages/negative aspects\n",
    "negative_system = \"\"\"You are an expert at analyzing food product reviews to identify disadvantages and drawbacks.\n",
    "Extract specific issues, complaints, or negative qualities mentioned in the review.\n",
    "Focus on aspects like taste problems, quality issues, value concerns, inconvenience factors, or health drawbacks.\n",
    "Be specific and detail-oriented in your analysis.\"\"\"\n",
    "\n",
    "negative_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", negative_system),\n",
    "    (\"human\", \"Review: {review}\\n\\nWhat specific disadvantages or drawbacks are mentioned in this review?\")\n",
    "])\n",
    "\n",
    "positive_analyzer = positive_prompt | llm | StrOutputParser()\n",
    "negative_analyzer = negative_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abdcf78-5a84-4543-80a5-3b3b25156ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_analyzer.invoke({\"review\":review_5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c154ed79-2a91-41de-bd72-701c86945871",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_analyzer.invoke({'review':review_1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12200a0c-a6e0-48fa-9e77-4953f291e7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"You are an expert food product analyst tasked with creating a comprehensive, balanced summary of a product.\n",
    "Based on the advantages and disadvantages provided, create a well-organized summary that helps consumers make an informed decision.\n",
    "Structure your response with clear sections for:\n",
    "1. Product Overview (brief description of what the product is)\n",
    "2. Key Advantages (organized by themes like taste, quality, value, etc.)\n",
    "3. Notable Disadvantages (organized by themes like taste, quality, value, etc.)\n",
    "4. Overall Assessment (balanced conclusion about the product)\n",
    "\n",
    "Be specific, balanced, and factual in your assessment.\"\"\"\n",
    "\n",
    "summary_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    (\"human\", \"Product: {product}\\n\\nAdvantages identified from positive reviews:\\n{advantages}\\n\\nDisadvantages identified from negative reviews:\\n{disadvantages}\\n\\nPlease create a comprehensive summary.\")\n",
    "])\n",
    "\n",
    "summary_generator = summary_prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4641e3d1-2ef1-4b23-a0fe-db6fe149a4b4",
   "metadata": {},
   "source": [
    "## Define the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45ba194-90f8-4f30-abfb-739cb24508e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "    \"\"\"\n",
    "    question: str\n",
    "    product: str\n",
    "    documents: List[Document]\n",
    "    review_scores: List[Dict[str, Any]]  # Each dict contains review text and its score\n",
    "    positive_reviews: List[str]\n",
    "    negative_reviews: List[str]\n",
    "    advantages: List[str]\n",
    "    disadvantages: List[str]\n",
    "    summary: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414cc756-f482-4df4-b6ee-7c2b92c90887",
   "metadata": {},
   "source": [
    "## Adding Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804c89db-334c-4210-8e26-72200c438e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_product(state):\n",
    "    \"\"\"Extract product name from question\"\"\"\n",
    "    print(\"---EXTRACTING PRODUCT NAME---\")\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    extract_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an assistant that extracts the specific food product name from a user question.\"),\n",
    "        (\"human\", \"From the following question, what is the specific food product being asked about? Return only the product name.\\n\\nQuestion: {question}\")\n",
    "    ])\n",
    "    \n",
    "    extract_chain = extract_prompt | llm | StrOutputParser()\n",
    "    product = extract_chain.invoke({\"question\": question})\n",
    "    \n",
    "    print(f\"Extracted product: {product}\")\n",
    "    return {\"question\": question, \"product\": product}\n",
    "\n",
    "# Node 2: Retrieve reviews\n",
    "def retrieve_reviews(state):\n",
    "    \"\"\"Retrieve reviews about the product\"\"\"\n",
    "    print(\"---RETRIEVING REVIEWS---\")\n",
    "    question = state[\"question\"]\n",
    "    product = state[\"product\"]\n",
    "    \n",
    "    # Create a search query focused on the product\n",
    "    search_query = f\"reviews about {product}\"\n",
    "    \n",
    "    # Retrieve documents\n",
    "    documents = retriever.invoke(search_query)\n",
    "    print(f\"Retrieved {len(documents)} reviews\")\n",
    "    \n",
    "    return {\"question\": question, \"product\": product, \"documents\": documents}\n",
    "\n",
    "# Node 3: Score reviews\n",
    "def score_reviews(state):\n",
    "    \"\"\"Score each review using the LoRA model\"\"\"\n",
    "    print(\"---SCORING REVIEWS---\")\n",
    "    documents = state[\"documents\"]\n",
    "    product = state[\"product\"]\n",
    "    \n",
    "    review_scores = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        review_text = doc.page_content\n",
    "        score = lora_scorer(review_text)\n",
    "        \n",
    "        review_scores.append({\n",
    "            \"review\": review_text,\n",
    "            \"score\": score\n",
    "        })\n",
    "        print(f\"Review scored: {score}/5\")\n",
    "    \n",
    "    # Separate positive and negative reviews\n",
    "    positive_reviews = [r[\"review\"] for r in review_scores if r[\"score\"] >= 4]\n",
    "    negative_reviews = [r[\"review\"] for r in review_scores if r[\"score\"] <= 3]\n",
    "    \n",
    "    print(f\"Found {len(positive_reviews)} positive reviews and {len(negative_reviews)} negative reviews\")\n",
    "    \n",
    "    return {\n",
    "        \"question\": state[\"question\"],\n",
    "        \"product\": product,\n",
    "        \"documents\": documents,\n",
    "        \"review_scores\": review_scores,\n",
    "        \"positive_reviews\": positive_reviews,\n",
    "        \"negative_reviews\": negative_reviews\n",
    "    }\n",
    "\n",
    "# Node 4: Analyze advantages\n",
    "def analyze_advantages(state):\n",
    "    \"\"\"Analyze positive reviews to extract advantages\"\"\"\n",
    "    print(\"---ANALYZING ADVANTAGES---\")\n",
    "    positive_reviews = state[\"positive_reviews\"]\n",
    "    product = state[\"product\"]\n",
    "    \n",
    "    advantages = []\n",
    "    \n",
    "    for review in positive_reviews:\n",
    "        advantage = positive_analyzer.invoke({\"review\": review})\n",
    "        advantages.append(advantage)\n",
    "        print(f\"Extracted advantage: {advantage[:50]}...\")\n",
    "    \n",
    "    return {\n",
    "        \"question\": state[\"question\"],\n",
    "        \"product\": product,\n",
    "        \"documents\": state[\"documents\"],\n",
    "        \"review_scores\": state[\"review_scores\"],\n",
    "        \"positive_reviews\": positive_reviews,\n",
    "        \"negative_reviews\": state[\"negative_reviews\"],\n",
    "        \"advantages\": advantages\n",
    "    }\n",
    "\n",
    "# Node 5: Analyze disadvantages\n",
    "def analyze_disadvantages(state):\n",
    "    \"\"\"Analyze negative reviews to extract disadvantages\"\"\"\n",
    "    print(\"---ANALYZING DISADVANTAGES---\")\n",
    "    negative_reviews = state[\"negative_reviews\"]\n",
    "    \n",
    "    disadvantages = []\n",
    "    \n",
    "    for review in negative_reviews:\n",
    "        disadvantage = negative_analyzer.invoke({\"review\": review})\n",
    "        disadvantages.append(disadvantage)\n",
    "        print(f\"Extracted disadvantage: {disadvantage[:50]}...\")\n",
    "    \n",
    "    return {\n",
    "        \"question\": state[\"question\"],\n",
    "        \"product\": state[\"product\"],\n",
    "        \"documents\": state[\"documents\"],\n",
    "        \"review_scores\": state[\"review_scores\"],\n",
    "        \"positive_reviews\": state[\"positive_reviews\"],\n",
    "        \"negative_reviews\": negative_reviews,\n",
    "        \"advantages\": state[\"advantages\"],\n",
    "        \"disadvantages\": disadvantages\n",
    "    }\n",
    "\n",
    "# Node 6: Generate summary\n",
    "def generate_summary(state):\n",
    "    \"\"\"Generate a comprehensive summary of advantages and disadvantages\"\"\"\n",
    "    print(\"---GENERATING SUMMARY---\")\n",
    "    product = state[\"product\"]\n",
    "    advantages = state[\"advantages\"]\n",
    "    disadvantages = state[\"disadvantages\"]\n",
    "    \n",
    "    advantages_text = \"\\n\".join([f\"- {adv}\" for adv in advantages])\n",
    "    disadvantages_text = \"\\n\".join([f\"- {dis}\" for dis in disadvantages])\n",
    "    \n",
    "    summary = summary_generator.invoke({\n",
    "        \"product\": product,\n",
    "        \"advantages\": advantages_text,\n",
    "        \"disadvantages\": disadvantages_text\n",
    "    })\n",
    "    \n",
    "    print(f\"Summary generated: {summary[:100]}...\")\n",
    "    \n",
    "    return {\n",
    "        \"question\": state[\"question\"],\n",
    "        \"product\": state[\"product\"],\n",
    "        \"documents\": state[\"documents\"],\n",
    "        \"review_scores\": state[\"review_scores\"],\n",
    "        \"positive_reviews\": state[\"positive_reviews\"],\n",
    "        \"negative_reviews\": state[\"negative_reviews\"],\n",
    "        \"advantages\": state[\"advantages\"],\n",
    "        \"disadvantages\": state[\"disadvantages\"],\n",
    "        \"summary\": summary\n",
    "    }\n",
    "\n",
    "def reformulate_query(state):\n",
    "    \"\"\"Reformulate the query to get better search results\"\"\"\n",
    "    print(\"---REFORMULATING QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    product = state[\"product\"]\n",
    "    \n",
    "    reformulate_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an expert at reformulating search queries to find more relevant information.\"),\n",
    "        (\"human\", \"I'm trying to find reviews about {product} but haven't found enough. Please reformulate this search query to find more relevant reviews: {question}\")\n",
    "    ])\n",
    "    \n",
    "    reformulate_chain = reformulate_prompt | llm | StrOutputParser()\n",
    "    new_query = reformulate_chain.invoke({\"product\": product, \"question\": question})\n",
    "    \n",
    "    print(f\"Reformulated query: {new_query}\")\n",
    "    \n",
    "    return {\n",
    "        \"question\": new_query,  # Update the question with the reformulated query\n",
    "        \"product\": state[\"product\"]\n",
    "    }\n",
    "\n",
    "def analyze_beverage(state):\n",
    "    \"\"\"Specialized analysis for beverage products\"\"\"\n",
    "    print(\"---SPECIALIZED BEVERAGE ANALYSIS---\")\n",
    "    positive_reviews = state[\"positive_reviews\"]\n",
    "    product = state[\"product\"]\n",
    "    \n",
    "    beverage_system = \"\"\"You are an expert beverage analyst specialized in analyzing coffee, tea, and other drink products.\n",
    "    Extract specific benefits and advantages mentioned in beverage reviews, with special attention to:\n",
    "    - Flavor profile and taste notes\n",
    "    - Brewing characteristics\n",
    "    - Aroma\n",
    "    - Aftertaste\n",
    "    - Consistency between cups/bottles\n",
    "    - Packaging quality\n",
    "    - Value for money\n",
    "    Be specific and detail-oriented in your analysis.\"\"\"\n",
    "    \n",
    "    beverage_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", beverage_system),\n",
    "        (\"human\", \"Product: {product}\\n\\nReview: {review}\\n\\nWhat specific advantages or positive aspects are mentioned in this beverage review?\")\n",
    "    ])\n",
    "    \n",
    "    beverage_chain = beverage_prompt | llm | StrOutputParser()\n",
    "    \n",
    "    advantages = []\n",
    "    for review in positive_reviews:\n",
    "        advantage = beverage_chain.invoke({\"product\": product, \"review\": review})\n",
    "        advantages.append(advantage)\n",
    "        print(f\"Extracted beverage advantage: {advantage[:50]}...\")\n",
    "    \n",
    "    return {\n",
    "        \"question\": state[\"question\"],\n",
    "        \"product\": product,\n",
    "        \"documents\": state[\"documents\"],\n",
    "        \"review_scores\": state[\"review_scores\"],\n",
    "        \"positive_reviews\": positive_reviews,\n",
    "        \"negative_reviews\": state[\"negative_reviews\"],\n",
    "        \"advantages\": advantages  # Store the advantages for later use\n",
    "    }\n",
    "\n",
    "def analyze_snack(state):\n",
    "    \"\"\"Specialized analysis for snack food products\"\"\"\n",
    "    print(\"---SPECIALIZED SNACK FOOD ANALYSIS---\")\n",
    "    positive_reviews = state[\"positive_reviews\"]\n",
    "    product = state[\"product\"]\n",
    "    \n",
    "    snack_system = \"\"\"You are an expert snack food analyst specialized in analyzing bars, chips, crackers, and other snack products.\n",
    "    Extract specific benefits and advantages mentioned in snack food reviews, with special attention to:\n",
    "    - Taste and flavor profile\n",
    "    - Texture and mouthfeel\n",
    "    - Freshness\n",
    "    - Portion size and packaging\n",
    "    - Nutritional benefits\n",
    "    - Convenience factors\n",
    "    - Value for money\n",
    "    Be specific and detail-oriented in your analysis.\"\"\"\n",
    "    \n",
    "    snack_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", snack_system),\n",
    "        (\"human\", \"Product: {product}\\n\\nReview: {review}\\n\\nWhat specific advantages or positive aspects are mentioned in this snack food review?\")\n",
    "    ])\n",
    "    \n",
    "    snack_chain = snack_prompt | llm | StrOutputParser()\n",
    "    \n",
    "    advantages = []\n",
    "    for review in positive_reviews:\n",
    "        advantage = snack_chain.invoke({\"product\": product, \"review\": review})\n",
    "        advantages.append(advantage)\n",
    "        print(f\"Extracted snack advantage: {advantage[:50]}...\")\n",
    "    \n",
    "    return {\n",
    "        \"question\": state[\"question\"],\n",
    "        \"product\": product,\n",
    "        \"documents\": state[\"documents\"],\n",
    "        \"review_scores\": state[\"review_scores\"],\n",
    "        \"positive_reviews\": positive_reviews,\n",
    "        \"negative_reviews\": state[\"negative_reviews\"],\n",
    "        \"advantages\": advantages  # Store the advantages for later use\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69a1a7c-b1b2-423c-a484-6b86ac0598f0",
   "metadata": {},
   "source": [
    "## Redefine the Nodes with base model without LoRA Fine Tuning (HuggingFaceTB/SmolLM2-1.7B-Instruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d710c578-0f8c-4bde-8fdb-412ae23cc548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 3: Score reviews\n",
    "def score_reviews_basic(state):\n",
    "    \"\"\"Score each review using the LoRA model\"\"\"\n",
    "    print(\"---SCORING REVIEWS---\")\n",
    "    documents = state[\"documents\"]\n",
    "    product = state[\"product\"]\n",
    "    \n",
    "    review_scores = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        review_text = doc.page_content\n",
    "        score = lora_scorer_base(review_text)\n",
    "        \n",
    "        review_scores.append({\n",
    "            \"review\": review_text,\n",
    "            \"score\": score\n",
    "        })\n",
    "        print(f\"Review scored: {score}/5\")\n",
    "    \n",
    "    # Separate positive and negative reviews\n",
    "    positive_reviews = [r[\"review\"] for r in review_scores if r[\"score\"] >= 4]\n",
    "    negative_reviews = [r[\"review\"] for r in review_scores if r[\"score\"] <= 2]\n",
    "    \n",
    "    print(f\"Found {len(positive_reviews)} positive reviews and {len(negative_reviews)} negative reviews\")\n",
    "    \n",
    "    return {\n",
    "        \"question\": state[\"question\"],\n",
    "        \"product\": product,\n",
    "        \"documents\": documents,\n",
    "        \"review_scores\": review_scores,\n",
    "        \"positive_reviews\": positive_reviews,\n",
    "        \"negative_reviews\": negative_reviews\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf04d7ea-8dec-4f77-b44d-7a191b70faec",
   "metadata": {},
   "source": [
    "## Adding Edge Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fed265-5c55-4318-b340-bebed84e0b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional functionality to consider adding:\n",
    "\n",
    "def check_review_count(state):\n",
    "    \"\"\"Determines whether enough reviews were found\"\"\"\n",
    "    if len(state[\"documents\"]) < 3:\n",
    "        print(\"---INSUFFICIENT REVIEWS FOUND, REFORMULATING QUERY---\")\n",
    "        return \"insufficient_reviews\"\n",
    "    else:\n",
    "        print(f\"---SUFFICIENT REVIEWS FOUND: {len(state['documents'])}---\")\n",
    "        return \"sufficient_reviews\"\n",
    "\n",
    "def determine_product_category(state):\n",
    "    \"\"\"Determines product category for specialized analysis\"\"\"\n",
    "    product = state[\"product\"].lower()\n",
    "    if \"coffee\" in product or \"tea\" in product or \"drink\" in product or \"water\" in product or \"juice\" in product:\n",
    "        print(f\"---PRODUCT CATEGORY: BEVERAGE---\")\n",
    "        return \"beverage\"\n",
    "    elif \"bar\" in product or \"snack\" in product or \"chip\" in product or \"cracker\" in product:\n",
    "        print(f\"---PRODUCT CATEGORY: SNACK FOOD---\")\n",
    "        return \"snack_food\"\n",
    "    else:\n",
    "        print(f\"---PRODUCT CATEGORY: GENERAL FOOD---\")\n",
    "        return \"general_food\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb41f7c-5005-40b4-a5c6-29ce690d5cd2",
   "metadata": {},
   "source": [
    "## Advanced Agentic workflow with base model without LoRA fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed1f8fd-cccf-4f5f-bbc3-edd778563c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building graph workflow...\")\n",
    "workflow_base = StateGraph(GraphState)\n",
    "\n",
    "workflow_base.add_node(\"extract_product\", extract_product)\n",
    "workflow_base.add_node(\"retrieve_reviews\", retrieve_reviews)\n",
    "workflow_base.add_node(\"score_reviews_basic\", score_reviews_basic)\n",
    "workflow_base.add_node(\"analyze_advantages\", analyze_advantages)\n",
    "workflow_base.add_node(\"analyze_disadvantages\", analyze_disadvantages)\n",
    "workflow_base.add_node(\"generate_summary\", generate_summary)\n",
    "workflow_base.add_node(\"reformulate_query\", reformulate_query)\n",
    "workflow_base.add_node(\"analyze_beverage\", analyze_beverage)\n",
    "workflow_base.add_node(\"analyze_snack\", analyze_snack)\n",
    "\n",
    "\n",
    "   # Add edges with conditions\n",
    "workflow_base.add_edge(START, \"extract_product\")\n",
    "workflow_base.add_edge(\"extract_product\", \"retrieve_reviews\")\n",
    "    \n",
    "    # Conditional edge: Check if we have enough reviews\n",
    "workflow_base.add_conditional_edges(\n",
    "        \"retrieve_reviews\",\n",
    "        check_review_count,\n",
    "        {\n",
    "            \"insufficient_reviews\": \"reformulate_query\",\n",
    "            \"sufficient_reviews\": \"score_reviews_basic\",\n",
    "        },\n",
    ")\n",
    "    \n",
    "    # Edge from reformulate_query back to retrieve_reviews\n",
    "workflow_base.add_edge(\"reformulate_query\", \"retrieve_reviews\")\n",
    "    \n",
    "    # Conditional edge: Route based on product category\n",
    "workflow_base.add_conditional_edges(\n",
    "        \"score_reviews_basic\",\n",
    "        determine_product_category,\n",
    "        {\n",
    "            \"beverage\": \"analyze_beverage\",\n",
    "            \"snack_food\": \"analyze_snack\",\n",
    "            \"general_food\": \"analyze_advantages\",\n",
    "        },\n",
    ")\n",
    "workflow_base.add_edge(\"analyze_beverage\", \"analyze_disadvantages\")\n",
    "workflow_base.add_edge(\"analyze_snack\", \"analyze_disadvantages\")\n",
    "workflow_base.add_edge(\"analyze_advantages\", \"analyze_disadvantages\")\n",
    "    \n",
    "    # Conditional edge: Check if we have enough data for a meaningful summary\n",
    "workflow_base.add_conditional_edges(\n",
    "        \"analyze_disadvantages\",\n",
    "        lambda state: \"sufficient_data\" \n",
    "                     if (len(state.get(\"advantages\", [])) > 0 or len(state.get(\"disadvantages\", [])) > 0) \n",
    "                     else \"insufficient_data\",\n",
    "        {\n",
    "            \"sufficient_data\": \"generate_summary\",\n",
    "            \"insufficient_data\": END,  # End with a default message if not enough data\n",
    "        },\n",
    ")\n",
    "    \n",
    "workflow_base.add_edge(\"generate_summary\", END)\n",
    "\n",
    "    # Compile\n",
    "app_base = workflow_base.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713bb62c-65d6-415a-87f8-e61e39a795c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    Image(\n",
    "        app_base.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065d81da-e01e-4682-a9f9-7d66e640a9e7",
   "metadata": {},
   "source": [
    "## Workflow for advanced agentic RAG with fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c778ae2-c788-4f69-9c03-179068ba098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building graph workflow...\")\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node(\"extract_product\", extract_product)\n",
    "workflow.add_node(\"retrieve_reviews\", retrieve_reviews)\n",
    "workflow.add_node(\"score_reviews\", score_reviews)\n",
    "workflow.add_node(\"analyze_advantages\", analyze_advantages)\n",
    "workflow.add_node(\"analyze_disadvantages\", analyze_disadvantages)\n",
    "workflow.add_node(\"generate_summary\", generate_summary)\n",
    "workflow.add_node(\"reformulate_query\", reformulate_query)\n",
    "workflow.add_node(\"analyze_beverage\", analyze_beverage)\n",
    "workflow.add_node(\"analyze_snack\", analyze_snack)\n",
    "\n",
    "\n",
    "   # Add edges with conditions\n",
    "workflow.add_edge(START, \"extract_product\")\n",
    "workflow.add_edge(\"extract_product\", \"retrieve_reviews\")\n",
    "    \n",
    "    # Conditional edge: Check if we have enough reviews\n",
    "workflow.add_conditional_edges(\n",
    "        \"retrieve_reviews\",\n",
    "        check_review_count,\n",
    "        {\n",
    "            \"insufficient_reviews\": \"reformulate_query\",\n",
    "            \"sufficient_reviews\": \"score_reviews\",\n",
    "        },\n",
    ")\n",
    "    \n",
    "    # Edge from reformulate_query back to retrieve_reviews\n",
    "workflow.add_edge(\"reformulate_query\", \"retrieve_reviews\")\n",
    "    \n",
    "    # Conditional edge: Route based on product category\n",
    "workflow.add_conditional_edges(\n",
    "        \"score_reviews\",\n",
    "        determine_product_category,\n",
    "        {\n",
    "            \"beverage\": \"analyze_beverage\",\n",
    "            \"snack_food\": \"analyze_snack\",\n",
    "            \"general_food\": \"analyze_advantages\",\n",
    "        },\n",
    ")\n",
    "workflow.add_edge(\"analyze_beverage\", \"analyze_disadvantages\")\n",
    "workflow.add_edge(\"analyze_snack\", \"analyze_disadvantages\")\n",
    "workflow.add_edge(\"analyze_advantages\", \"analyze_disadvantages\")\n",
    "    \n",
    "    # Conditional edge: Check if we have enough data for a meaningful summary\n",
    "workflow.add_conditional_edges(\n",
    "        \"analyze_disadvantages\",\n",
    "        lambda state: \"sufficient_data\" \n",
    "                     if (len(state.get(\"advantages\", [])) > 0 or len(state.get(\"disadvantages\", [])) > 0) \n",
    "                     else \"insufficient_data\",\n",
    "        {\n",
    "            \"sufficient_data\": \"generate_summary\",\n",
    "            \"insufficient_data\": END,  # End with a default message if not enough data\n",
    "        },\n",
    ")\n",
    "    \n",
    "workflow.add_edge(\"generate_summary\", END)\n",
    "\n",
    "    # Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de868e06-44e3-4b63-be2d-4d85af3a4c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a881875a-1028-40d0-a728-babe7581a91f",
   "metadata": {},
   "source": [
    "# Discussion of output evolution\n",
    "\n",
    "\n",
    "### Base LLM\n",
    "- Provides generic, knowledge-based responses without specific context\n",
    "- Shows confusion in Questions\n",
    "- Delivers structured but somewhat formulaic lists of advantages and disadvantages\n",
    "- Limited to general knowledge without access to specific product reviews or experiences\n",
    "\n",
    "### Basic RAG\n",
    "- Shows noticeable improvement with retrieval of relevant information\n",
    "- Responses are significantly briefer but more product-specific\n",
    "- Provides some authentic details that aren't in the base LLM's knowledge\n",
    "- Less comprehensive but more grounded in actual product information\n",
    "\n",
    "### Advanced RAG with Base Model\n",
    "- Significant jump in response quality with detailed assessments\n",
    "- Well-structured with formatting (bold headers) and cohesive narratives\n",
    "- Synthesizes information into an overall assessment rather than isolated pros/cons\n",
    "- More nuanced analysis considering multiple factors (taste, convenience, price point)\n",
    "- A key drawback however, is the base model's ability to evaluate the score for the emotion is really bad\n",
    "- It can only extracts advantages, not disadvantages at all\n",
    "- This will give biased Evaluation\n",
    "\n",
    "### Advanced RAG with LoRA Fine-tuned Model\n",
    "- Most refined responses with enhanced structure (markdown headers)\n",
    "- Better balance of positive attributes and potential drawbacks\n",
    "- More specific in addressing target audiences and use cases\n",
    "- Includes conditional recommendations based on consumer preferences\n",
    "- Improved organization with clearer separation of assessment points\n",
    "\n",
    "## Key Improvements and Progression\n",
    "\n",
    "1. **Information Quality**: Evolves from generic knowledge to specific, retrieved product insights\n",
    "2. **Contextual Understanding**: Increasingly incorporates authentic user experiences and perspectives\n",
    "3. **Response Structure**: Advances from simple lists to well-organized, cohesive narratives\n",
    "4. **Analytical Depth**: Progresses from surface-level observations to nuanced analysis considering multiple factors\n",
    "5. **Relevance**: Becomes more targeted to the actual products in question with each enhancement\n",
    "\n",
    "## Impact of Fine-tuning\n",
    "\n",
    "The fine-tuned model demonstrates several qualitative improvements:\n",
    "- More consistent structured format with clear section headings\n",
    "- Better articulation of specific product attributes and considerations\n",
    "- More balanced presentation of positives and potential drawbacks\n",
    "- Inclusion of specific consumer considerations for making purchase decisions\n",
    "- More natural transitioning between different aspects of the assessment\n",
    "\n",
    "The progression clearly illustrates how each enhancement layer adds value to the response quality, with the advanced RAG using a LoRA fine-tuned model delivering the most sophisticated, balanced, and useful product assessments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fc4507-74d2-4725-bd97-4e32ea44a55f",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a6056c-03dd-4522-8a11-9dd18dd9fa1c",
   "metadata": {},
   "source": [
    "## Base LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88faca4-b04f-4457-a54a-f89cad2bed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are the advantages and disadvantages of KIND Bars?\"\n",
    "\n",
    "# Create a simple prompt template for just the question\n",
    "prompt_template = \"\"\"\n",
    "Answer the following question on foods based on your knowledge:\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# Create the LLM and chain\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", seed=0)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Invoke the chain\n",
    "print(f\"Querying base LLM: {question}\")\n",
    "response = chain.invoke({\"question\": question})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b531b850-a2a5-4382-93da-4a15ee9d81c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are the advantages and disadvantages of KIND Bars?\"\n",
    "docs = retriever.invoke(question)\n",
    "retrieved_docs = docs[0].page_content\n",
    "context = \"\\n\\n\".join(retrieved_docs)\n",
    "\n",
    "# Get the RAG prompt\n",
    "template_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# Create the LLM and chain\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", seed=0)\n",
    "chain = template_prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"question\": question, \"context\": context})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab2027a-2d77-4f71-9f83-a2905cfba24d",
   "metadata": {},
   "source": [
    "## Advanced RAG with base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f9fc8e-4b9d-49c4-b788-c2841323a075",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "runconfig = {\"recursion_limit\": 50}\n",
    "inputs = {\"question\": \"What are the advantages and disadvantages of KIND Bars?\"}\n",
    "for output in app_base.stream(inputs, config=runconfig):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "pprint(value[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac487838-43a5-41fc-8dee-53d5af9bbf50",
   "metadata": {},
   "source": [
    "## Advanced RAG with fine tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2a6c21-4cf0-463c-a49b-2ccd207bd707",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "runconfig = {\"recursion_limit\": 50}\n",
    "inputs = {\"question\": \"What are the advantages and disadvantages of KIND Bars?\"}\n",
    "for output in app.stream(inputs, config=runconfig):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "pprint(value[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb10189-3e47-4937-b778-e71a97341c76",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "## Base LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ae3ca2-2ad3-44fc-85e5-a43526d1300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tell me about the pros and cons of Haagen-Dazs Ice Cream\"\n",
    "# Create a simple prompt template for just the question\n",
    "prompt_template = \"\"\"\n",
    "Answer the following question on foods based on your knowledge:\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# Create the LLM and chain\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", seed=0)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Invoke the chain\n",
    "print(f\"Querying base LLM: {question}\")\n",
    "response = chain.invoke({\"question\": question})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d06dcf-e97b-4226-a2c0-d35b6e57624b",
   "metadata": {},
   "source": [
    "## Basic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353da3f2-7fc9-4f41-8aec-1dffb6726eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tell me about the pros and cons of Haagen-Dazs Ice Cream\"\n",
    "docs = retriever.invoke(question)\n",
    "retrieved_docs = docs[0].page_content\n",
    "context = \"\\n\\n\".join(retrieved_docs)\n",
    "\n",
    "# Get the RAG prompt\n",
    "template_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# Create the LLM and chain\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", seed=0)\n",
    "chain = template_prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"question\": question, \"context\": context})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c715e47a-b55d-4c40-8492-90f3ce4f4578",
   "metadata": {},
   "source": [
    "## Advanced RAG with base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3ea72d-efbe-4b49-9b40-6998d0159620",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tell me about the pros and cons of Haagen-Dazs Ice Cream\"\n",
    "runconfig = {\"recursion_limit\": 50}\n",
    "inputs = {\"question\": question}\n",
    "for output in app_base.stream(inputs, config=runconfig):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "pprint(value[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52813450-11e9-4c70-811f-5d3e28a2689b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "question = \"Tell me about the pros and cons of Haagen-Dazs Ice Cream\"\n",
    "runconfig = {\"recursion_limit\": 50}\n",
    "inputs = {\"question\": question}\n",
    "for output in app.stream(inputs, config=runconfig):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "pprint(value[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb4ee43-e5d6-4a94-b30b-73c9a3c1d861",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "## Base LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b5887-214c-443d-a436-6ba1d6fad20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tell me about the if I should use Starbucks brand coffee as my daily coffee\"\n",
    "# Create a simple prompt template for just the question\n",
    "prompt_template = \"\"\"\n",
    "Answer the following question on foods based on your knowledge:\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# Create the LLM and chain\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", seed=0)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Invoke the chain\n",
    "print(f\"Querying base LLM: {question}\")\n",
    "response = chain.invoke({\"question\": question})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0143d930-474c-454a-9935-11c6119f4db4",
   "metadata": {},
   "source": [
    "## Basic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269b1a68-1604-44a6-b4d9-0d0df0ceaef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tell me about the if I should use Starbucks brand coffee as my daily coffee\"\n",
    "docs = retriever.invoke(question)\n",
    "retrieved_docs = docs[0].page_content\n",
    "context = \"\\n\\n\".join(retrieved_docs)\n",
    "\n",
    "# Get the RAG prompt\n",
    "template_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# Create the LLM and chain\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", seed=0)\n",
    "chain = template_prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"question\": question, \"context\": context})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf46071-5883-463b-a64a-0b7c54b4946a",
   "metadata": {},
   "source": [
    "## Advanced RAG With Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d49354-b532-4b08-ba71-9503c481ed0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "question = \"Tell me about the if I should use Starbucks brand coffee as my daily coffee\"\n",
    "runconfig = {\"recursion_limit\": 50}\n",
    "inputs = {\"question\": question}\n",
    "for output in app_base.stream(inputs, config=runconfig):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "pprint(value[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ee2ff0-a863-4bb2-88af-03573f875591",
   "metadata": {},
   "source": [
    "## Advanced RAG with Lora Fine Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70adad5e-1681-4a7c-8c79-8e48d7fb6fa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "question = \"Tell me about the if I should use Starbucks brand coffee as my daily coffee\"\n",
    "runconfig = {\"recursion_limit\": 50}\n",
    "inputs = {\"question\": question}\n",
    "for output in app.stream(inputs, config=runconfig):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "pprint(value[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbc5ef4-cf4f-41db-b790-0af0af26f4ba",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "## Base LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aef8e4-ee0d-4c27-8cbb-c8b79cc2beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What should I know if I want to buy San Pellegrino Sparkling Water for Party\"\n",
    "# Create a simple prompt template for just the question\n",
    "prompt_template = \"\"\"\n",
    "Answer the following question on foods based on your knowledge:\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# Create the LLM and chain\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", seed=0)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Invoke the chain\n",
    "print(f\"Querying base LLM: {question}\")\n",
    "response = chain.invoke({\"question\": question})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e7986b-36b4-4c55-aec6-3d38ab083b81",
   "metadata": {},
   "source": [
    "## Basic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0871b927-f3d0-4c87-ab5c-e66f98f71ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What should I know if I want to buy San Pellegrino Sparkling Water for Party\"\n",
    "docs = retriever.invoke(question)\n",
    "retrieved_docs = docs[0].page_content\n",
    "context = \"\\n\\n\".join(retrieved_docs)\n",
    "\n",
    "# Get the RAG prompt\n",
    "template_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# Create the LLM and chain\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", seed=0)\n",
    "chain = template_prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"question\": question, \"context\": context})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269667b3-7ff8-40e1-9e18-3678eea28280",
   "metadata": {},
   "source": [
    "## Advanced agentic RAG with base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc577c6c-ba7e-406b-8555-163bd519b86c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "question = \"What should I know if I want to buy San Pellegrino Sparkling Water for Party\"\n",
    "runconfig = {\"recursion_limit\": 50}\n",
    "inputs = {\"question\": question}\n",
    "for output in app_base.stream(inputs, config=runconfig):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "pprint(value[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c830689b-d850-4db4-b68c-40d2664f1e09",
   "metadata": {},
   "source": [
    "## Advanced agentic RAG with Lora Fine Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fceaad1-485d-4647-80ee-4036bfd523b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "question = \"What should I know if I want to buy San Pellegrino Sparkling Water for Party\"\n",
    "runconfig = {\"recursion_limit\": 50}\n",
    "inputs = {\"question\": question}\n",
    "for output in app.stream(inputs, config=runconfig):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "pprint(value[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d68b73-26b7-427c-a147-4a9abb5b7597",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "## Base LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacf4119-2791-4d1e-87b4-d0268dc9c497",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What brand of milk contains most nutritions and protein\"\n",
    "# Create a simple prompt template for just the question\n",
    "prompt_template = \"\"\"\n",
    "Answer the following question on foods based on your knowledge:\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# Create the LLM and chain\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", seed=0)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Invoke the chain\n",
    "print(f\"Querying base LLM: {question}\")\n",
    "response = chain.invoke({\"question\": question})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c851b89-b464-4737-87bd-d22b8054e6b9",
   "metadata": {},
   "source": [
    "## Basic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc472d27-7b3c-4972-95dc-62f93e2a6ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What brand of milk contains most nutritions and protein\"\n",
    "docs = retriever.invoke(question)\n",
    "retrieved_docs = docs[0].page_content\n",
    "context = \"\\n\\n\".join(retrieved_docs)\n",
    "\n",
    "# Get the RAG prompt\n",
    "template_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# Create the LLM and chain\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", seed=0)\n",
    "chain = template_prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"question\": question, \"context\": context})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1a1695-c962-4a69-a23f-eed0e0bbac38",
   "metadata": {},
   "source": [
    "## Advanced RAG with base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ac6f6-fa4a-4b92-a75b-1760c2f34a8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "question = \"What brand of milk contains most nutritions and protein\"\n",
    "runconfig = {\"recursion_limit\": 50}\n",
    "inputs = {\"question\": question}\n",
    "for output in app_base.stream(inputs, config=runconfig):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "pprint(value[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f888447e-419c-4cef-86c2-9558844f49b9",
   "metadata": {},
   "source": [
    "## Advanced RAG with LoRA fine tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58a8dfc-a468-47ab-92d5-52878122b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What brand of milk contains most nutritions and protein\"\n",
    "runconfig = {\"recursion_limit\": 50}\n",
    "inputs = {\"question\": question}\n",
    "for output in app.stream(inputs, config=runconfig):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "pprint(value[\"summary\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
